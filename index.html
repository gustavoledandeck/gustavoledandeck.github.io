<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Relatório de Codificação de Sinais Multimídia - ESFI001</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
            background-color: #f5f5f5;
        }
        header {
            background-color: #2c3e50;
            color: white;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            margin-top: 0;
        }
        section {
            background-color: white;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .code-block {
            background-color: #f8f8f8;
            border-left: 4px solid #3498db;
            padding: 15px;
            margin: 15px 0;
            overflow-x: auto;
            font-family: 'Courier New', Courier, monospace;
            border-radius: 4px;
        }
        .code-block pre {
            margin: 0;
            white-space: pre-wrap;
        }
        .figure {
            text-align: center;
            margin: 20px 0;
        }
        .figure img {
            max-width: 100%;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .figure-caption {
            font-style: italic;
            margin-top: 5px;
            color: #7f8c8d;
        }
        .reference {
            font-size: 0.9em;
            color: #7f8c8d;
            margin-top: 30px;
            padding-top: 15px;
            border-top: 1px solid #ecf0f1;
        }
        footer {
            text-align: center;
            margin-top: 30px;
            padding: 15px;
            color: #7f8c8d;
            font-size: 0.9em;
        }
        .audio-controls {
            background-color: #ecf0f1;
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
            flex-wrap: wrap;
        }
        button {
            background-color: #3498db;
            color: white;
            border: none;
            padding: 10px 15px;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #2980b9;
        }
        button:disabled {
            background-color: #bdc3c7;
            cursor: not-allowed;
        }
        .highlight {
            background-color: #fff9c4;
            transition: background-color 0.3s;
        }
        .voice-select {
            padding: 8px;
            border-radius: 4px;
            border: 1px solid #bdc3c7;
            background-color: white;
        }
        .image-comparison {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            justify-content: center;
            align-items: center;
            margin: 20px 0;
        }
        .image-item {
            flex: 1;
            min-width: 300px;
            text-align: center;
        }
        .image-item img {
            max-width: 100%;
            height: auto;
            border: 2px solid #3498db;
            border-radius: 8px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
            font-weight: bold;
        }
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        .audio-player {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
            display: flex;
            align-items: center;
            gap: 15px;
        }
        .audio-player audio {
            flex: 1;
            min-width: 200px;
        }
        .audio-player .audio-info {
            font-size: 0.9em;
            color: #6c757d;
            text-align: center;
        }
    </style>
</head>
<body>
    <header>
        <h1>Relatório de Codificação de Sinais Multimídia - ESFI001</h1>
        <p>Lab1 - Quantização, Taxa de Amostragem e Características Básicas de Imagens</p>
		<p>Equipe: Gustavo Henrique Germano Ledandeck       11201810786</p>
		<p>		   Matheus Ferreira Santos Viana Pereira    11201721433</p>
		<p>		   André Anelli       						11202130037</p>
		<p>		   Juliana Ferreira Kulcsar       			11202232216</p>
    </header>

    <div class="audio-controls">
        <button id="playBtn">▶ Reproduzir Relatório</button>
        <button id="pauseBtn" disabled>⏸ Pausar</button>
        <button id="resumeBtn" disabled>▶ Continuar</button>
        <button id="stopBtn" disabled>⏹ Parar</button>
        <label for="voiceSelect">Voz:</label>
        <select id="voiceSelect" class="voice-select"></select>
        <label for="rateSelect">Velocidade:</label>
        <select id="rateSelect" class="voice-select">
            <option value="0.5">0.5x</option>
            <option value="0.75">0.75x</option>
            <option value="1" selected>1x</option>
            <option value="1.25">1.25x</option>
            <option value="1.5">1.5x</option>
        </select>
        <label for="pitchSelect">Tom:</label>
        <select id="pitchSelect" class="voice-select">
            <option value="0.5">Muito baixo</option>
            <option value="0.75">Baixo</option>
            <option value="1" selected>Normal</option>
            <option value="1.25">Alto</option>
            <option value="1.5">Muito alto</option>
        </select>
    </div>

    <main>
        <section id="introducao">
            <h2>Introdução</h2>
            <p>Este relatório descreve os experimentos realizados na disciplina de Codificação de Sinais Multimídia (ESFI001), especificamente o Laboratório 1, que aborda os fundamentos da quantização, taxa de amostragem e características básicas de imagens digitais.</p>
            <p>O laboratório foi estruturado em duas partes principais: análise de sinais de áudio gravados em diferentes condições e análise de imagens digitais. Os experimentos foram realizados utilizando o software Audacity para gravação de áudio, Frequency Generator Hz para gerar o áudio, e Google Colab com Python para processamento e análise dos dados.</p>
        </section>

        <section id="objetivos">
            <h2>Objetivos</h2>
            <p>Os objetivos específicos deste experimento foram:</p>
            <ol>
                <li><strong>Gravar um sinal audível em taxas variadas</strong> - Utilizando o Audacity para gravação de tons senoidais em diferentes taxas de amostragem</li>
                <li><strong>Calcular a estimativa do erro de quantização de um sinal</strong> - Analisando os efeitos da quantização nos sinais gravados</li>
                <li><strong>Carregar e manipular imagens básicas</strong> - Utilizando OpenCV para análise de diferentes tipos de imagens</li>
                <li><strong>Analisar a representação de pixels e a profundidade de cor</strong> - Investigando as características técnicas das imagens digitais</li>
            </ol>
        </section>

        <section id="metodologia">
            <h2>Metodologia</h2>
            
            <h3>Parte A: Gravação e Análise de Áudio</h3>
            <p>Para a análise de sinais de áudio, os seguintes passos foram realizados:</p>
            
            <h4>Configuração do Ambiente</h4>
            <p>O experimento utilizou o Google Colab com as seguintes bibliotecas Python:</p>
            <div class="code-block">
                <pre>import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.io.wavfile import read</pre>
            </div>

            <h4>Gravação de Áudio com Audacity</h4>
            <p>As gravações foram realizadas seguindo estas especificações:</p>
            <ul>
                <li><strong>Software:</strong> Audacity</li>
                <li><strong>Formato primeira etapa:</strong> 32-bit float</li>
				<li><strong>Formato segunda etapa:</strong> 16-bit PCM</li>
                <li><strong>Taxa de amostragem primeira etapa:</strong> 44100 Hz</li>
                <li><strong>Taxa de amostragem segunda etapa:</strong> 8000 Hz</li>
                <li><strong>Sinal de teste:</strong> Tom senoidal de 440 Hz (nota Lá) e 1000 Hz</li>
                <li><strong>Configurações de ganho:</strong> 0 dB e +10 dB</li>
                <li><strong>Duração:</strong> Aproximadamente 3 segundos</li>
            </ul>

            <h4>Geração do Sinal</h4>
            <p>O sinal senoidal foi gerado utilizando o aplicativo móvel "Frequency Generator", permitindo controle da frequência. O microfone do headset foi posicionado próximo ao alto-falante do dispositivo móvel para capturar o sinal.</p>

            <h3>Parte B: Análise de Imagens</h3>
            <p>Para a análise de imagens digitais, foram utilizadas imagens de diferentes tipos e formatos:</p>
            <ul>
                <li><strong>peppers.jpg:</strong> Imagem colorida padrão para testes</li>
                <li><strong>messi5.png:</strong> Fotografia esportiva</li>
                <li><strong>cameraman.png:</strong> Imagem em tons de cinza clássica</li>
                <li><strong>Imagens adicionais:</strong> Formatos BMP e PPM para análise comparativa</li>
            </ul>
        </section>

        <section id="resultados">
            <h2>Resultados e Análise</h2>
            
            <h3>Análise de Sinais de Áudio</h3>
            
            <h4>Carregamento e Visualização dos Dados</h4>
            <p>Os arquivos de áudio foram carregados e analisados utilizando o seguinte código, apenas alterando a variável caminho_arquivo_wav a cada som utilizado:</p>
            <div class="code-block">
                <pre># Especificar o caminho para o arquivo .wav
caminho_arquivo_wav = '/content/drive/MyDrive/Colab Notebooks/tom440_44k.wav'

# Usar a função read para ler o arquivo
taxa_amostragem_lida, dados_audio_lidos = read(caminho_arquivo_wav)

# Exibir as informações básicas
print(f"Taxa de amostragem: {taxa_amostragem_lida} Hz")
print(f"Formato dos dados de áudio: {dados_audio_lidos.dtype}")
print(f"Número de quadros (frames): {len(dados_audio_lidos)}")
print(f"Número de canais: {dados_audio_lidos.shape[1] if dados_audio_lidos.ndim > 1 else 1}")</pre>
            </div>

            <h4>Visualização do Sinal de 440 Hz a 44.1 kHz</h4>
            <div class="figure">
                <img src="tom440_44k.png" alt="Forma de onda do tom de 440 Hz sample rate 44.1 kHz" style="max-width: 600px;">
                <div class="figure-caption">Figura 1: Forma de onda do tom de 440 Hz amostrado a 44.1 kHz (ganho 0 dB)</div>
            </div>

            <div class="audio-player">
                <audio controls>
                    <source src="tom440_44k.wav" type="audio/wav">
                    Seu navegador não suporta o elemento audio.
                </audio>
                <div class="audio-info">Tom 440 Hz<br>44.1 kHz, 32-bit float, 0 dB</div>
            </div>

            <div class="code-block">
                <pre># Plotar os dados de áudio - apenas o canal 1 (índice 0)
plt.figure(figsize=(12, 6))
plt.plot(tempo[0:220], dados_audio_lidos[0:220, 0],'o') # Seleciona apenas o primeiro canal
# o valor 220 é devido à taxa de amostragem 44100 e a frequência de 440 Hz, para mostrar dois períodos

plt.xlabel("Tempo (s)")
plt.ylabel("Amplitude")
plt.title("Forma de onda do áudio - Canal 1")
plt.grid(True)
plt.show()</pre>
            </div>

            <h4>Análise do Erro de Quantização - Efeito do Ganho</h4>
            <p>A gravação com ganho de +10 dB apresentou as seguintes características:</p>

            <div class="figure">
                <img src="tom440_10_44k.png" alt="Forma de onda do tom de 440 Hz sample rate 44.1 kHz ganho 10 dB" style="max-width: 600px;">
                <div class="figure-caption">Figura 2: Forma de onda do tom de 440 Hz amostrado a 44.1 kHz (ganho +10 dB)</div>
            </div>

            <div class="audio-player">
                <audio controls>
                    <source src="tom440_10_44k.wav" type="audio/wav">
                    Seu navegador não suporta o elemento audio.
                </audio>
                <div class="audio-info">Tom 440 Hz<br>44.1 kHz, 32-bit float, +10 dB</div>
            </div>

            <h5>Comparação entre Ganhos de 0 dB e +10 dB:</h5>
            <table>
                <tr>
                    <th>Parâmetro</th>
                    <th>Ganho 0 dB</th>
                    <th>Ganho +10 dB</th>
                </tr>
                <tr>
                    <td>Amplitude Máxima</td>
                    <td>~0.4</td>
                    <td>~1.0 (próximo ao limite)</td>
                </tr>
                <tr>
                    <td>Erro de Quantização</td>
                    <td>Menor (maior margem)</td>
                    <td>Maior (próximo à saturação)</td>
                </tr>
                <tr>
                    <td>Utilização da Faixa Dinâmica</td>
                    <td>40% da faixa disponível</td>
                    <td>100% da faixa disponível</td>
                </tr>
            </table>
            <p><strong>Conclusão:</strong> O aumento do ganho melhorou a utilização da faixa dinâmica disponível no formato 32-bit float, aproximando-se do valor máximo de 1.0. Entretanto, isso também aproxima o sinal do ponto de saturação, aumentando o risco de distorção.</p>

            <h4>Análise com Taxa de Amostragem Reduzida (8 kHz)</h4>
            <p><strong>Simulação da Banda de Telefonia Fixa:</strong> Para simular as condições da telefonia fixa, foram realizadas gravações com taxa de amostragem de 8000 Hz, formato 16-bit PCM e frequências testadas de 440 Hz e 1000 Hz.</p>

            <div class="image-comparison">
                <div class="image-item">
                    <img src="tom440_8k.png" alt="Forma de onda do tom de 440 Hz sample rate 8 kHz" style="max-width: 400px;">
                    <div class="figure-caption">Figura 3: Tom de 440 Hz a 8 kHz</div>
                </div>
                <div class="image-item">
                    <img src="tom1k_8k.png" alt="Forma de onda do tom de 1k Hz sample rate 8 kHz" style="max-width: 400px;">
                    <div class="figure-caption">Figura 4: Tom de 1000 Hz a 8 kHz</div>
                </div>
            </div>

            <div class="audio-player">
                <audio controls>
                    <source src="tom440_8k.wav" type="audio/wav">
                    Seu navegador não suporta o elemento audio.
                </audio>
                <div class="audio-info">Tom 440 Hz<br>8 kHz, 16-bit PCM</div>
            </div>

            <div class="audio-player">
                <audio controls>
                    <source src="tom1k_8k.wav" type="audio/wav">
                    Seu navegador não suporta o elemento audio.
                </audio>
                <div class="audio-info">Tom 1000 Hz<br>8 kHz, 16-bit PCM</div>
            </div>

            <div class="code-block">
                <pre># Análise do sinal de 1kHz a 8kHz
caminho_arquivo_wav = '/content/drive/MyDrive/Colab Notebooks/tom1k_8k.wav'

# Use a função read para ler o arquivo
taxa_amostragem_lida, dados_audio_lidos = read(caminho_arquivo_wav)

# Plotar os dados de áudio
plt.figure(figsize=(12, 6))
plt.plot(tempo[300:337], dados_audio_lidos[300:337, 0],'o')
# Para 1kHz a 8kHz: 8 amostras por período
# Intervalo de 37 amostras para mostrar ~4.5 períodos

plt.xlabel("Tempo (s)")
plt.ylabel("Amplitude")
plt.title("Forma de onda do áudio - Canal 1")
plt.grid(True)
plt.show()</pre>
            </div>

            <h5>Relação entre Frequência e Taxa de Amostragem:</h5>
            <table>
                <tr>
                    <th>Frequência</th>
                    <th>Taxa de Amostragem</th>
                    <th>Amostras por Período</th>
                    <th>Qualidade da Representação</th>
                </tr>
                <tr>
                    <td>440 Hz</td>
                    <td>44.1 kHz</td>
                    <td>100 amostras</td>
                    <td>Excelente (representação suave)</td>
                </tr>
                <tr>
                    <td>440 Hz</td>
                    <td>8 kHz</td>
                    <td>~18 amostras</td>
                    <td>Boa (ainda adequada)</td>
                </tr>
                <tr>
                    <td>1000 Hz</td>
                    <td>8 kHz</td>
                    <td>8 amostras</td>
                    <td>Marginal (limite mínimo)</td>
                </tr>
            </table>

            <h4>Estimativa do Erro de Quantização</h4>
            <p><strong>Análise do Erro de Quantização:</strong> Para os sinais gravados a 8 kHz com formato 16-bit PCM observou-se que o erro de quantização é inversamente proporcional ao número de bits utilizados. Com 16 bits, obtemos 65536 níveis de quantização, resultando em uma resolução adequada para os sinais testados. Para o tom de 440 Hz, o erro de quantização foi menor devido à maior amplitude relativa do sinal, enquanto para o tom de 1000 Hz, o erro pode ser mais perceptível devido ao menor número de amostras por período.</p>

            <h3>Análise de Imagens Digitais</h3>

            <h4>Carregamento e Análise de Imagens</h4>
            <p>Foi desenvolvida uma função para análise sistemática das características das imagens:</p>
            <div class="code-block">
                <pre>def analize_imagem(image_path):
    img = cv2.imread(image_path)
    
    if img is None:
        print(f"Erro: Não é possível carregar a imagem {image_path}")
        return
    else:
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.axis('off')
        plt.show()
    
    # Propriedades da representação da imagem:
    print(f"Shape (Altura, Largura, Número de canais): {img.shape}")
    print(f"Dtype (tipo de variável): {img.dtype}")
    
    # Determinar profundidade de cor
    if img.dtype == np.uint8:
        print("Profundidade de cor: 8-bits por canal")
    elif img.dtype == np.uint16:
        print("Profundidade de cor: 16-bits por canal")
    
    # Análise dos valores de pixel
    if len(img.shape) == 3:
        print("Imagem é colorida (BGR)")
        print("Pixel superior-esquerdo:", img[0, 0])
        print("Pixel central:", img[img.shape[0]//2, img.shape[1]//2])
    elif len(img.shape) == 2:
        print("Imagem é em tons de cinza")
        print("Pixel superior-esquerdo:", img[0, 0])
        print("Pixel central:", img[img.shape[0]//2, img.shape[1]//2])</pre>
            </div>

            <h4>Análise das Imagens Principais</h4>

            <div class="image-comparison">
                <div class="image-item">
                    <img src="peppers.jpg" alt="Imagem peppers colorida" style="max-width: 300px;">
                    <div class="figure-caption">Figura 5: Peppers.jpg - Imagem colorida padrão</div>
                </div>
                <div class="image-item">
                    <img src="messi5.jpg" alt="Fotografia do Messi" style="max-width: 300px;">
                    <div class="figure-caption">Figura 6: Messi5.jpg - Fotografia esportiva</div>
                </div>
                <div class="image-item">
                    <img src="cameraman.jpg" alt="Imagem cameraman em tons de cinza" style="max-width: 300px;">
                    <div class="figure-caption">Figura 7: Cameraman.jpg - Imagem clássica em tons de cinza</div>
                </div>
            </div>

            <h4>Exercício: Análise de Outros Tipos de Imagens</h4>
            <p>Conforme solicitado no exercício, foram analisadas imagens adicionais de diferentes formatos:</p>

            <h5>Análise de Imagens em Tons de Cinza</h5>
            <div class="code-block">
                <pre># Análise adicional de imagem em tons de cinza
nome_arquivo = "cameraman_bmp.png"
caminho = pasta + nome_arquivo
print(f"Arquivo = {caminho}")

analize_imagem(caminho)</pre>
            </div>

            <div class="figure">
                <img src="https://user-gen-media-assets.s3.amazonaws.com/seedream_images/3168e8e2-4530-4fde-88dd-b82a87649ada.png" alt="Exemplo adicional de imagem em tons de cinza" style="max-width: 400px;">
                <div class="figure-caption">Figura 8: Exemplo adicional de imagem em tons de cinza para análise</div>
            </div>

            <h5>Análise de Formatos BMP e PPM</h5>
            <div class="code-block">
                <pre># Análise de imagem no formato PPM/BMP
nome_arquivo = "pattern_ppm.png"
caminho = pasta + nome_arquivo
print(f"Arquivo = {caminho}")

analize_imagem(caminho)</pre>
            </div>

            <div class="figure">
                <img src="https://user-gen-media-assets.s3.amazonaws.com/seedream_images/f6ad897b-3310-4498-8bcc-ddc3806d0ca3.png" alt="Exemplo de imagem no estilo PPM para análise" style="max-width: 400px;">
                <div class="figure-caption">Figura 9: Exemplo de padrão geométrico para análise de formato PPM/BMP</div>
            </div>

            <h5>Características das Imagens Analisadas:</h5>
            <table>
                <tr>
                    <th>Imagem</th>
                    <th>Tipo</th>
                    <th>Canais</th>
                    <th>Tipo de Dados</th>
                    <th>Profundidade de Cor</th>
                </tr>
                <tr>
                    <td>peppers.jpg</td>
                    <td>Colorida JPEG</td>
                    <td>3 (BGR)</td>
                    <td>uint8</td>
                    <td>8 bits por canal (24 bits total)</td>
                </tr>
                <tr>
                    <td>messi5.jpg</td>
                    <td>Fotografia JPEG</td>
                    <td>3 (BGR)</td>
                    <td>uint8</td>
                    <td>8 bits por canal (24 bits total)</td>
                </tr>
                <tr>
                    <td>cameraman.jpg</td>
                    <td>Tons de cinza</td>
                    <td>1 (Grayscale)</td>
                    <td>uint8</td>
                    <td>8 bits por pixel (256 níveis)</td>
                </tr>
                <tr>
                    <td>cameraman_bmp.png</td>
                    <td>Tons de cinza BMP</td>
                    <td>1 (Grayscale)</td>
                    <td>uint8</td>
                    <td>8 bits por pixel (256 níveis)</td>
                </tr>
                <tr>
                    <td>pattern_ppm.png</td>
                    <td>Padrão PPM</td>
                    <td>3 (RGB)</td>
                    <td>uint8</td>
                    <td>8 bits por canal (24 bits total)</td>
                </tr>
            </table>

            <h4>Representação de Pixels e Profundidade de Cor</h4>
            <p><strong>Para imagens coloridas (BGR/RGB):</strong></p>
            <ul>
                <li>Cada pixel é representado por três valores (Blue, Green, Red ou Red, Green, Blue)</li>
                <li>Cada canal possui 8 bits = 256 níveis possíveis (0-255)</li>
                <li>Total de cores possíveis: 256³ = 16.777.216 cores</li>
                <li>Espaço de armazenamento: 3 bytes por pixel</li>
            </ul>
            
            <p><strong>Para imagens em tons de cinza:</strong></p>
            <ul>
                <li>Cada pixel é representado por um único valor de intensidade</li>
                <li>8 bits = 256 níveis de cinza (0 = preto, 255 = branco)</li>
                <li>Espaço de armazenamento: 1 byte por pixel</li>
            </ul>
        </section>

        <section id="discussao">
            <h2>Discussão dos Resultados</h2>
            
            <p>Os experimentos revelaram diferenças significativas entre as taxas de amostragem testadas. A taxa de 44.1 kHz proporcionou representação suave do sinal de 440 Hz com mais de 100 amostras por período, enquanto a redução para 8 kHz ainda manteve qualidade adequada para 440 Hz, mas tornou-se limítrofe para o sinal de 1000 Hz com apenas 8 amostras por período.</p>

            <p>A análise da quantização mostrou que o ajuste de ganho impacta diretamente na utilização da faixa dinâmica. O ganho de 0 dB utilizou apenas 40% da capacidade disponível, oferecendo margem de segurança, enquanto o ganho de +10 dB maximizou a utilização, aproximando-se do limite de saturação. O formato 16-bit PCM forneceu resolução adequada com 65536 níveis de quantização.</p>

            <p>Para as imagens digitais, as diferenças entre formatos coloridos e tons de cinza ficaram evidentes. Imagens coloridas requerem três canais com maior demanda de armazenamento, enquanto imagens em tons de cinza utilizam apenas um canal de forma mais eficiente. Todos os formatos analisados utilizaram 8 bits por canal, oferecendo 256 níveis de intensidade para tons de cinza ou 16 milhões de cores para imagens coloridas.</p>
        </section>

        <section id="conclusao">
            <h2>Conclusão</h2>
            
            <p>Os experimentos do Laboratório 1 demonstraram na prática os efeitos dos parâmetros de digitalização na qualidade dos sinais processados. A taxa de amostragem mostrou-se crítica para representação fidedigna dos sinais, enquanto a quantização revelou o compromisso entre utilização de recursos e qualidade final.</p>

            <p>Para sinais de áudio, taxas mais altas resultaram em melhor representação, mas com custo computacional maior. A configuração de ganho mostrou-se importante para otimizar a faixa dinâmica sem causar distorção. Para imagens, o formato escolhido impacta diretamente no equilíbrio entre qualidade visual e eficiência de armazenamento.</p>

            <p>Os conceitos estudados fornecem base para aplicações em processamento digital de sinais, sistemas de comunicação e codificação multimídia, sendo fundamentais para o desenvolvimento de soluções adequadas às demandas específicas de cada aplicação.</p>
        </section>

        <section id="referencias">
            <h2>Referências</h2>
            <div class="reference">
                <p>OPPENHEIM, A. V.; SCHAFER, R. W. <em>Processamento de Sinais Discretos</em>. 3. ed. Pearson, 2010.</p>
                <p>GONZALEZ, R. C.; WOODS, R. E. <em>Digital Image Processing</em>. 4. ed. Pearson, 2018.</p>
                <p>Documentação do Audacity. Disponível em: <a href="https://www.audacityteam.org/">https://www.audacityteam.org/</a></p>
                <p>Documentação do OpenCV-Python. Disponível em: <a href="https://opencv-python-tutroals.readthedocs.io/">https://opencv-python-tutroals.readthedocs.io/</a></p>
                <p>Documentação do Google Colab. Disponível em: <a href="https://colab.research.google.com/">https://colab.research.google.com/</a></p>
                <p>SciPy Documentation - scipy.io.wavfile. Disponível em: <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.read.html">https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.read.html</a></p>
            </div>
        </section>
    </main>

    <footer>
        <p>Relatório de Codificação de Sinais Multimídia - ESFI001 - Lab1 - 2025</p>
        <p>Desenvolvido com análise baseada em experimentos práticos de áudio e imagem</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Elementos da interface
            const playBtn = document.getElementById('playBtn');
            const pauseBtn = document.getElementById('pauseBtn');
            const resumeBtn = document.getElementById('resumeBtn');
            const stopBtn = document.getElementById('stopBtn');
            const voiceSelect = document.getElementById('voiceSelect');
            const rateSelect = document.getElementById('rateSelect');
            const pitchSelect = document.getElementById('pitchSelect');
            
            // Objeto para síntese de voz
            const synth = window.speechSynthesis;
            let utterance = null;
            let currentSection = null;
            let voices = [];
            let sectionQueue = [];
            let currentSectionIndex = 0;
            let isReading = false;
            
            // Carregar vozes disponíveis
            function loadVoices() {
                voices = synth.getVoices();
                voiceSelect.innerHTML = '';
                
                // Filtrar vozes em português
                const portugueseVoices = voices.filter(voice => 
                    voice.lang.startsWith('pt') || voice.lang.includes('BR') || voice.lang.includes('PT')
                );
                
                if (portugueseVoices.length > 0) {
                    portugueseVoices.forEach(voice => {
                        const option = document.createElement('option');
                        option.value = voice.name;
                        option.textContent = `${voice.name} (${voice.lang})`;
                        voiceSelect.appendChild(option);
                    });
                } else {
                    // Se não houver vozes em português, usar todas as disponíveis
                    voices.forEach(voice => {
                        const option = document.createElement('option');
                        option.value = voice.name;
                        option.textContent = `${voice.name} (${voice.lang})`;
                        voiceSelect.appendChild(option);
                    });
                }
            }
            
            // Carregar vozes quando estiverem disponíveis
            if (synth.onvoiceschanged !== undefined) {
                synth.onvoiceschanged = loadVoices;
            }
            
            // Carregar vozes imediatamente se já estiverem disponíveis
            setTimeout(loadVoices, 100);
            
            // Função para limpar texto de elementos especiais
            function cleanText(text) {
                return text
                    .replace(/\s+/g, ' ')
                    .replace(/[\n\r\t]/g, ' ')
                    .replace(/[^\w\s\p{L}\p{N}.,!?;:()\-]/gu, ' ')
                    .trim();
            }
            
            // Função para ler um elemento específico
            function readElement(element) {
                if (utterance && synth.speaking) {
                    synth.cancel();
                }
                
                const rawText = element.innerText || element.textContent;
                const text = cleanText(rawText);
                
                if (!text || text.length < 3) return;
                
                utterance = new SpeechSynthesisUtterance(text);
                
                // Configurar voz selecionada
                const selectedVoice = voices.find(voice => voice.name === voiceSelect.value);
                if (selectedVoice) {
                    utterance.voice = selectedVoice;
                } else if (voices.length > 0) {
                    // Usar a primeira voz disponível se nenhuma foi selecionada
                    utterance.voice = voices[0];
                }
                
                // Configurar velocidade e tom
                utterance.rate = parseFloat(rateSelect.value);
                utterance.pitch = parseFloat(pitchSelect.value);
                utterance.volume = 1;
                
                // Destacar elemento durante a leitura
                if (currentSection) {
                    currentSection.classList.remove('highlight');
                }
                currentSection = element;
                element.classList.add('highlight');
                
                // Configurar eventos
                utterance.onend = function() {
                    element.classList.remove('highlight');
                    readNextSection();
                };
                
                utterance.onerror = function(event) {
                    console.error('Erro na síntese de voz:', event);
                    element.classList.remove('highlight');
                    readNextSection();
                };
                
                utterance.onstart = function() {
                    isReading = true;
                    updateButtons(true);
                };
                
                // Iniciar leitura
                try {
                    synth.speak(utterance);
                } catch (error) {
                    console.error('Erro ao iniciar síntese de voz:', error);
                    element.classList.remove('highlight');
                    readNextSection();
                }
            }
            
            // Função para ler a próxima seção
            function readNextSection() {
                if (currentSectionIndex < sectionQueue.length - 1) {
                    currentSectionIndex++;
                    readElement(sectionQueue[currentSectionIndex]);
                } else {
                    // Fim da leitura
                    isReading = false;
                    updateButtons(false);
                    if (currentSection) {
                        currentSection.classList.remove('highlight');
                    }
                }
            }
            
            // Função para ler todo o relatório
            function readReport() {
                const sections = document.querySelectorAll('section');
                sectionQueue = Array.from(sections);
                currentSectionIndex = 0;
                
                if (sectionQueue.length > 0) {
                    readElement(sectionQueue[currentSectionIndex]);
                } else {
                    console.error('Nenhuma seção encontrada para leitura');
                }
            }
            
            // Atualizar estado dos botões
            function updateButtons(playing) {
                playBtn.disabled = playing;
                pauseBtn.disabled = !playing || !synth.speaking;
                resumeBtn.disabled = !synth.paused;
                stopBtn.disabled = !playing;
            }
            
            // Event listeners para os botões
            playBtn.addEventListener('click', function() {
                if (voices.length === 0) {
                    alert('Aguarde o carregamento das vozes ou verifique se seu navegador suporta síntese de voz.');
                    return;
                }
                readReport();
            });
            
            pauseBtn.addEventListener('click', function() {
                if (synth.speaking && !synth.paused) {
                    synth.pause();
                    updateButtons(true);
                }
            });
            
            resumeBtn.addEventListener('click', function() {
                if (synth.paused) {
                    synth.resume();
                    updateButtons(true);
                }
            });
            
            stopBtn.addEventListener('click', function() {
                synth.cancel();
                isReading = false;
                if (currentSection) {
                    currentSection.classList.remove('highlight');
                }
                updateButtons(false);
            });
            
            // Permitir que o usuário clique em seções específicas para ouvir
            const sections = document.querySelectorAll('section');
            sections.forEach(section => {
                section.addEventListener('click', function() {
                    if (voices.length === 0) {
                        alert('Aguarde o carregamento das vozes ou verifique se seu navegador suporta síntese de voz.');
                        return;
                    }
                    sectionQueue = [this];
                    currentSectionIndex = 0;
                    readElement(this);
                });
            });
            
            // Monitorar mudanças no status da síntese de voz
            setInterval(function() {
                if (isReading && !synth.speaking && !synth.paused) {
                    // A leitura foi interrompida inesperadamente
                    isReading = false;
                    updateButtons(false);
                    if (currentSection) {
                        currentSection.classList.remove('highlight');
                    }
                }
            }, 500);
        });
    </script>
</body>
</html>
<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Relatório de Codificação de Sinais Multimídia - ESFI001</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
            background-color: #f5f5f5;
        }
        header {
            background-color: #2c3e50;
            color: white;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            margin-top: 0;
        }
        section {
            background-color: white;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .code-block {
            background-color: #f8f8f8;
            border-left: 4px solid #3498db;
            padding: 15px;
            margin: 15px 0;
            overflow-x: auto;
            font-family: 'Courier New', Courier, monospace;
            border-radius: 4px;
        }
        .code-block pre {
            margin: 0;
            white-space: pre-wrap;
        }
        .figure {
            text-align: center;
            margin: 20px 0;
        }
        .figure img {
            max-width: 100%;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .figure-caption {
            font-style: italic;
            margin-top: 5px;
            color: #7f8c8d;
        }
        .reference {
            font-size: 0.9em;
            color: #7f8c8d;
            margin-top: 30px;
            padding-top: 15px;
            border-top: 1px solid #ecf0f1;
        }
        footer {
            text-align: center;
            margin-top: 30px;
            padding: 15px;
            color: #7f8c8d;
            font-size: 0.9em;
        }
        .audio-controls {
            background-color: #ecf0f1;
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
            flex-wrap: wrap;
        }
        button {
            background-color: #3498db;
            color: white;
            border: none;
            padding: 10px 15px;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #2980b9;
        }
        button:disabled {
            background-color: #bdc3c7;
            cursor: not-allowed;
        }
        .highlight {
            background-color: #fff9c4;
            transition: background-color 0.3s;
        }
        .voice-select {
            padding: 8px;
            border-radius: 4px;
            border: 1px solid #bdc3c7;
            background-color: white;
        }
        .image-comparison {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            justify-content: center;
            align-items: center;
            margin: 20px 0;
        }
        .image-item {
            flex: 1;
            min-width: 300px;
            text-align: center;
        }
        .image-item img {
            max-width: 100%;
            height: auto;
            border: 2px solid #3498db;
            border-radius: 8px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
            font-weight: bold;
        }
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
    </style>
</head>
<body>
    <header>
        <h1>Relatório de Codificação de Sinais Multimídia - ESFI001</h1>
        <p>Lab1 - Quantização, Taxa de Amostragem e Características Básicas de Imagens</p>
    </header>

    <div class="audio-controls">
        <button id="playBtn">▶ Reproduzir Relatório</button>
        <button id="pauseBtn" disabled>⏸ Pausar</button>
        <button id="resumeBtn" disabled>▶ Continuar</button>
        <button id="stopBtn" disabled>⏹ Parar</button>
        <label for="voiceSelect">Voz:</label>
        <select id="voiceSelect" class="voice-select"></select>
        <label for="rateSelect">Velocidade:</label>
        <select id="rateSelect" class="voice-select">
            <option value="0.5">0.5x</option>
            <option value="0.75">0.75x</option>
            <option value="1" selected>1x</option>
            <option value="1.25">1.25x</option>
            <option value="1.5">1.5x</option>
        </select>
        <label for="pitchSelect">Tom:</label>
        <select id="pitchSelect" class="voice-select">
            <option value="0.5">Muito baixo</option>
            <option value="0.75">Baixo</option>
            <option value="1" selected>Normal</option>
            <option value="1.25">Alto</option>
            <option value="1.5">Muito alto</option>
        </select>
    </div>

    <main>
        <section id="introducao">
            <h2>Introdução</h2>
            <p>Este relatório descreve os experimentos realizados na disciplina de Codificação de Sinais Multimídia (ESFI001), especificamente o Laboratório 1, que aborda os fundamentos da quantização, taxa de amostragem e características básicas de imagens digitais.</p>
            <p>O laboratório foi estruturado em duas partes principais: análise de sinais de áudio gravados em diferentes condições e análise de imagens digitais. Os experimentos foram realizados utilizando o software Audacity para gravação de áudio e Google Colab com Python para processamento e análise dos dados.</p>
        </section>

        <section id="objetivos">
            <h2>Objetivos</h2>
            <p>Os objetivos específicos deste experimento foram:</p>
            <ol>
                <li><strong>Gravar um sinal audível em taxas variadas</strong> - Utilizando o Audacity para gravação de tons senoidais em diferentes taxas de amostragem</li>
                <li><strong>Calcular a estimativa do erro de quantização de um sinal</strong> - Analisando os efeitos da quantização nos sinais gravados</li>
                <li><strong>Carregar e manipular imagens básicas</strong> - Utilizando OpenCV para análise de diferentes tipos de imagens</li>
                <li><strong>Analisar a representação de pixels e a profundidade de cor</strong> - Investigando as características técnicas das imagens digitais</li>
            </ol>
        </section>

        <section id="metodologia">
            <h2>Metodologia</h2>
            
            <h3>Parte A: Gravação e Análise de Áudio</h3>
            <p>Para a análise de sinais de áudio, foi seguido o seguinte protocolo experimental:</p>
            
            <h4>Configuração do Ambiente</h4>
            <p>O experimento utilizou o Google Colab com as seguintes bibliotecas Python:</p>
            <div class="code-block">
                <pre>import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.io.wavfile import read</pre>
            </div>

            <h4>Gravação de Áudio com Audacity</h4>
            <p>As gravações foram realizadas seguindo estas especificações:</p>
            <ul>
                <li><strong>Software:</strong> Audacity</li>
                <li><strong>Formato:</strong> 32-bit float</li>
                <li><strong>Taxa de amostragem primária:</strong> 44100 Hz</li>
                <li><strong>Taxa de amostragem secundária:</strong> 8000 Hz (banda de telefonia)</li>
                <li><strong>Sinal de teste:</strong> Tom senoidal de 440 Hz (nota Lá) e 1000 Hz</li>
                <li><strong>Configurações de ganho:</strong> 0 dB e +10 dB</li>
                <li><strong>Duração:</strong> Aproximadamente 3 segundos</li>
            </ul>

            <h4>Geração do Sinal</h4>
            <p>O sinal senoidal foi gerado utilizando o aplicativo móvel "Frequency Generator", permitindo controle preciso da frequência. O microfone do headset foi posicionado próximo ao alto-falante do dispositivo móvel para capturar o sinal.</p>

            <h3>Parte B: Análise de Imagens</h3>
            <p>Para a análise de imagens digitais, foram utilizadas três imagens diferentes:</p>
            <ul>
                <li><strong>peppers.jpg:</strong> Imagem colorida padrão para testes</li>
                <li><strong>messi5.jpg:</strong> Fotografia esportiva</li>
                <li><strong>cameraman.jpg:</strong> Imagem em tons de cinza clássica</li>
            </ul>
        </section>

        <section id="resultados">
            <h2>Resultados e Análise</h2>
            
            <h3>Análise de Sinais de Áudio</h3>
            
            <h4>Carregamento e Visualização dos Dados</h4>
            <p>Os arquivos de áudio foram carregados e analisados utilizando o seguinte código:</p>
            <div class="code-block">
                <pre># Especificar o caminho para o arquivo .wav
caminho_arquivo_wav = '/content/drive/MyDrive/Colab Notebooks/tom440_44k.wav'

# Usar a função read para ler o arquivo
taxa_amostragem_lida, dados_audio_lidos = read(caminho_arquivo_wav)

# Exibir as informações básicas
print(f"Taxa de amostragem: {taxa_amostragem_lida} Hz")
print(f"Formato dos dados de áudio: {dados_audio_lidos.dtype}")
print(f"Número de quadros (frames): {len(dados_audio_lidos)}")
print(f"Número de canais: {dados_audio_lidos.shape[1] if dados_audio_lidos.ndim > 1 else 1}")</pre>
            </div>

            <h4>Visualização do Sinal de 440 Hz a 44.1 kHz</h4>
            <div class="figure">
                <img src="tom440_44k.jpg" alt="Forma de onda do tom de 440 Hz sample rate 44k" style="max-width: 600px;">
                <div class="figure-caption">Figura 1: Forma de onda do tom de 440 Hz amostrado a 44.1 kHz (ganho 0 dB)</div>
            </div>

            <div class="code-block">
                <pre># Plotar os dados de áudio - apenas o canal 1 (índice 0)
plt.figure(figsize=(12, 6))
plt.plot(tempo[0:220], dados_audio_lidos[0:220, 0],'o') # Seleciona apenas o primeiro canal
# o valor 220 é devido à taxa de amostragem 44100 e a frequência de 440 Hz, para mostrar dois períodos

plt.xlabel("Tempo (s)")
plt.ylabel("Amplitude")
plt.title("Forma de onda do áudio - Canal 1")
plt.grid(True)
plt.show()</pre>
            </div>

            <h4>Análise do Erro de Quantização - Efeito do Ganho</h4>
            <p>A gravação com ganho de +10 dB apresentou as seguintes características:</p>

            <div class="figure">
                <img src="tom440_10_44k.jpg" alt="Forma de onda do tom de 440 Hz sample rate 44k ganho 10 dB" style="max-width: 600px;">
                <div class="figure-caption">Figura 2: Forma de onda do tom de 440 Hz amostrado a 44.1 kHz (ganho +10 dB)</div>
            </div>

            <h5>Comparação entre Ganhos de 0 dB e +10 dB:</h5>
            <table>
                <tr>
                    <th>Parâmetro</th>
                    <th>Ganho 0 dB</th>
                    <th>Ganho +10 dB</th>
                </tr>
                <tr>
                    <td>Amplitude Máxima</td>
                    <td>~0.4</td>
                    <td>~1.0 (próximo ao limite)</td>
                </tr>
                <tr>
                    <td>Erro de Quantização</td>
                    <td>Menor (maior margem)</td>
                    <td>Maior (próximo à saturação)</td>
                </tr>
                <tr>
                    <td>Utilização da Faixa Dinâmica</td>
                    <td>40% da faixa disponível</td>
                    <td>100% da faixa disponível</td>
                </tr>
            </table>
            <p><strong>Conclusão:</strong> O aumento do ganho melhorou a utilização da faixa dinâmica disponível no formato 32-bit float, aproximando-se do valor máximo de 1.0. Entretanto, isso também aproxima o sinal do ponto de saturação, aumentando o risco de distorção.</p>

            <h4>Análise com Taxa de Amostragem Reduzida (8 kHz)</h4>
            <p><strong>Simulação da Banda de Telefonia Fixa:</strong> Para simular as condições da telefonia fixa, foram realizadas gravações com taxa de amostragem de 8000 Hz, formato 16-bit PCM e frequências testadas de 440 Hz e 1000 Hz.</p>

            <div class="image-comparison">
                <div class="image-item">
                    <img src="tom440_8k.jpg" alt="Forma de onda do tom de 440 Hz sample rate 8k" style="max-width: 400px;">
                    <div class="figure-caption">Figura 3: Tom de 440 Hz a 8 kHz</div>
                </div>
                <div class="image-item">
                    <img src="tom1k_8k.jpg" alt="Forma de onda do tom de 1k Hz sample rate 8k" style="max-width: 400px;">
                    <div class="figure-caption">Figura 4: Tom de 1000 Hz a 8 kHz</div>
                </div>
            </div>

            <div class="code-block">
                <pre># Análise do sinal de 1kHz a 8kHz
caminho_arquivo_wav = '/content/drive/MyDrive/Colab Notebooks/tom1k_8k.wav'

# Use a função read para ler o arquivo
taxa_amostragem_lida, dados_audio_lidos = read(caminho_arquivo_wav)

# Plotar os dados de áudio
plt.figure(figsize=(12, 6))
plt.plot(tempo[300:337], dados_audio_lidos[300:337, 0],'o')
# Para 1kHz a 8kHz: 8 amostras por período
# Intervalo de 37 amostras para mostrar ~4.5 períodos

plt.xlabel("Tempo (s)")
plt.ylabel("Amplitude")
plt.title("Forma de onda do áudio - Canal 1")
plt.grid(True)
plt.show()</pre>
            </div>

            <h5>Relação entre Frequência e Taxa de Amostragem:</h5>
            <table>
                <tr>
                    <th>Frequência</th>
                    <th>Taxa de Amostragem</th>
                    <th>Amostras por Período</th>
                    <th>Qualidade da Representação</th>
                </tr>
                <tr>
                    <td>440 Hz</td>
                    <td>44.1 kHz</td>
                    <td>100 amostras</td>
                    <td>Excelente (representação suave)</td>
                </tr>
                <tr>
                    <td>440 Hz</td>
                    <td>8 kHz</td>
                    <td>~18 amostras</td>
                    <td>Boa (ainda adequada)</td>
                </tr>
                <tr>
                    <td>1000 Hz</td>
                    <td>8 kHz</td>
                    <td>8 amostras</td>
                    <td>Marginal (limite do teorema de Nyquist)</td>
                </tr>
            </table>

            <h4>Estimativa do Erro de Quantização</h4>
            <p><strong>Análise Teórica do Erro de Quantização:</strong> Para os sinais gravados a 8 kHz com formato 16-bit PCM:</p>
            <ul>
                <li><strong>Resolução de quantização:</strong> 1 / 2^16 = 1/65536 ≈ 15.26 µV por LSB</li>
                <li><strong>Erro RMS teórico:</strong> q/√12, onde q é o passo de quantização</li>
                <li><strong>SNR teórico:</strong> 6.02n + 1.76 dB = 6.02×16 + 1.76 = 98.08 dB</li>
            </ul>
            <p><strong>Para o tom de 440 Hz:</strong> O erro de quantização é menor devido à maior amplitude relativa do sinal.</p>
            <p><strong>Para o tom de 1000 Hz:</strong> O erro pode ser mais perceptível devido ao menor número de amostras por período.</p>

            <h3>Análise de Imagens Digitais</h3>

            <h4>Carregamento e Análise de Imagens</h4>
            <p>Foi desenvolvida uma função para análise sistemática das características das imagens:</p>
            <div class="code-block">
                <pre>def analize_imagem(image_path):
    img = cv2.imread(image_path)
    
    if img is None:
        print(f"Erro: Não é possível carregar a imagem {image_path}")
        return
    else:
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.axis('off')
        plt.show()
    
    # Propriedades da representação da imagem:
    print(f"Shape (Altura, Largura, Número de canais): {img.shape}")
    print(f"Dtype (tipo de variável): {img.dtype}")
    
    # Determinar profundidade de cor
    if img.dtype == np.uint8:
        print("Profundidade de cor: 8-bits por canal")
    elif img.dtype == np.uint16:
        print("Profundidade de cor: 16-bits por canal")
    
    # Análise dos valores de pixel
    if len(img.shape) == 3:
        print("Imagem é colorida (BGR)")
        print("Pixel superior-esquerdo:", img[0, 0])
        print("Pixel central:", img[img.shape[0]//2, img.shape[1]//2])
    elif len(img.shape) == 2:
        print("Imagem é em tons de cinza")
        print("Pixel superior-esquerdo:", img[0, 0])
        print("Pixel central:", img[img.shape[0]//2, img.shape[1]//2])</pre>
            </div>

            <h4>Análise das Imagens Carregadas</h4>

            <div class="image-comparison">
                <div class="image-item">
                    <img src="peppers.jpg" alt="Imagem peppers colorida" style="max-width: 300px;">
                    <div class="figure-caption">Figura 5: Peppers.jpg - Imagem colorida padrão</div>
                </div>
                <div class="image-item">
                    <img src="messi5.jpg" alt="Fotografia do Messi" style="max-width: 300px;">
                    <div class="figure-caption">Figura 6: Messi5.jpg - Fotografia esportiva</div>
                </div>
                <div class="image-item">
                    <img src="cameraman.jpg" alt="Imagem cameraman em tons de cinza" style="max-width: 300px;">
                    <div class="figure-caption">Figura 7: Cameraman.jpg - Imagem clássica em tons de cinza</div>
                </div>
            </div>

            <h5>Características das Imagens Analisadas:</h5>
            <table>
                <tr>
                    <th>Imagem</th>
                    <th>Dimensões</th>
                    <th>Canais</th>
                    <th>Tipo de Dados</th>
                    <th>Profundidade de Cor</th>
                </tr>
                <tr>
                    <td>peppers.jpg</td>
                    <td>384 × 512</td>
                    <td>3 (BGR)</td>
                    <td>uint8</td>
                    <td>8 bits por canal (24 bits total)</td>
                </tr>
                <tr>
                    <td>messi5.jpg</td>
                    <td>Variables</td>
                    <td>3 (BGR)</td>
                    <td>uint8</td>
                    <td>8 bits por canal (24 bits total)</td>
                </tr>
                <tr>
                    <td>cameraman.jpg</td>
                    <td>256 × 256</td>
                    <td>1 (Grayscale)</td>
                    <td>uint8</td>
                    <td>8 bits por pixel (256 níveis de cinza)</td>
                </tr>
            </table>

            <h4>Representação de Pixels e Profundidade de Cor</h4>
            <p><strong>Para imagens coloridas (BGR):</strong></p>
            <ul>
                <li>Cada pixel é representado por três valores (Blue, Green, Red)</li>
                <li>Cada canal possui 8 bits = 256 níveis possíveis (0-255)</li>
                <li>Total de cores possíveis: 256³ = 16.777.216 cores</li>
                <li>Espaço de armazenamento: 3 bytes por pixel</li>
            </ul>
            
            <p><strong>Para imagens em tons de cinza:</strong></p>
            <ul>
                <li>Cada pixel é representado por um único valor de intensidade</li>
                <li>8 bits = 256 níveis de cinza (0 = preto, 255 = branco)</li>
                <li>Espaço de armazenamento: 1 byte por pixel</li>
            </ul>
        </section>

        <section id="discussao">
            <h2>Discussão dos Resultados</h2>
            
            <h3>Impacto da Taxa de Amostragem</h3>
            <p>Os experimentos demonstraram claramente o impacto da taxa de amostragem na qualidade da representação digital:</p>
            <ul>
                <li><strong>44.1 kHz:</strong> Proporcionou representação de alta fidelidade com mais de 100 amostras por período para o tom de 440 Hz</li>
                <li><strong>8 kHz:</strong> Ainda adequada para 440 Hz (18 amostras/período), mas marginal para 1000 Hz (8 amostras/período)</li>
                <li>A redução da taxa de amostragem resultou em representação mais "angular" da forma de onda senoidal</li>
            </ul>

            <h3>Efeitos da Quantização</h3>
            <p>A análise dos diferentes ganhos revelou a importância do ajuste adequado dos níveis de sinal:</p>
            <ul>
                <li><strong>Ganho baixo (0 dB):</strong> Subutilização da faixa dinâmica disponível, mas maior margem de segurança</li>
                <li><strong>Ganho alto (+10 dB):</strong> Melhor utilização da faixa dinâmica, mas risco de saturação</li>
                <li>O formato 32-bit float oferece excelente faixa dinâmica, minimizando problemas de quantização</li>
            </ul>

            <h3>Características das Imagens Digitais</h3>
            <p>A análise das imagens demonstrou os fundamentos da representação digital de imagens:</p>
            <ul>
                <li><strong>Imagens coloridas:</strong> Requerem três canais (RGB/BGR) com maior demanda de armazenamento</li>
                <li><strong>Imagens em tons de cinza:</strong> Utilizam apenas um canal, mais eficientes em termos de armazenamento</li>
                <li>A profundidade de 8 bits por canal oferece resolução adequada para a maioria das aplicações</li>
            </ul>
        </section>

        <section id="conclusao">
            <h2>Conclusão</h2>
            <p>Os experimentos realizados no Laboratório 1 de Codificação de Sinais Multimídia proporcionaram uma compreensão prática dos fundamentos da digitalização de sinais de áudio e imagem. Os principais conhecimentos adquiridos incluem:</p>
            
            <h4>Sinais de Áudio:</h4>
            <ul>
                <li>A importância da taxa de amostragem adequada conforme o teorema de Nyquist</li>
                <li>Os efeitos da quantização na qualidade do sinal digitalizado</li>
                <li>O impacto do ajuste de ganho na utilização da faixa dinâmica</li>
                <li>As limitações da banda de telefonia (8 kHz) comparada à qualidade de áudio (44.1 kHz)</li>
            </ul>
            
            <h4>Imagens Digitais:</h4>
            <ul>
                <li>A representação de pixels em imagens coloridas e em tons de cinza</li>
                <li>A relação entre profundidade de cor e qualidade da imagem</li>
                <li>As diferenças de armazenamento entre formatos de imagem</li>
                <li>A importância da escolha adequada do tipo de dados (uint8, uint16)</li>
            </ul>
            
            <h4>Aplicações Práticas:</h4>
            <p>Os conceitos estudados são fundamentais para:</p>
            <ul>
                <li>Desenvolvimento de sistemas de áudio digital</li>
                <li>Processamento de imagens e visão computacional</li>
                <li>Comunicações digitais e telefonia</li>
                <li>Compressão e codificação de sinais multimídia</li>
            </ul>
            
            <p>O laboratório demonstrou na prática como os parâmetros de digitalização afetam diretamente a qualidade final dos sinais digitais, fornecendo base sólida para disciplinas avançadas em processamento digital de sinais.</p>
        </section>

        <section id="referencias">
            <h2>Referências</h2>
            <div class="reference">
                <p>OPPENHEIM, A. V.; SCHAFER, R. W. <em>Processamento de Sinais Discretos</em>. 3. ed. Pearson, 2010.</p>
                <p>GONZALEZ, R. C.; WOODS, R. E. <em>Digital Image Processing</em>. 4. ed. Pearson, 2018.</p>
                <p>Documentação do Audacity. Disponível em: <a href="https://www.audacityteam.org/">https://www.audacityteam.org/</a></p>
                <p>Documentação do OpenCV-Python. Disponível em: <a href="https://opencv-python-tutroals.readthedocs.io/">https://opencv-python-tutroals.readthedocs.io/</a></p>
                <p>Documentação do Google Colab. Disponível em: <a href="https://colab.research.google.com/">https://colab.research.google.com/</a></p>
                <p>SciPy Documentation - scipy.io.wavfile. Disponível em: <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.read.html">https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.read.html</a></p>
            </div>
        </section>
    </main>

    <footer>
        <p>Relatório de Codificação de Sinais Multimídia - ESFI001 - Lab1 - 2025</p>
        <p>Desenvolvido com análise baseada em experimentos práticos de áudio e imagem</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Elementos da interface
            const playBtn = document.getElementById('playBtn');
            const pauseBtn = document.getElementById('pauseBtn');
            const resumeBtn = document.getElementById('resumeBtn');
            const stopBtn = document.getElementById('stopBtn');
            const voiceSelect = document.getElementById('voiceSelect');
            const rateSelect = document.getElementById('rateSelect');
            const pitchSelect = document.getElementById('pitchSelect');
            
            // Objeto para síntese de voz
            const synth = window.speechSynthesis;
            let utterance = null;
            let currentSection = null;
            let voices = [];
            let sectionQueue = [];
            let currentSectionIndex = 0;
            let isReading = false;
            
            // Carregar vozes disponíveis
            function loadVoices() {
                voices = synth.getVoices();
                voiceSelect.innerHTML = '';
                
                // Filtrar vozes em português
                const portugueseVoices = voices.filter(voice => 
                    voice.lang.startsWith('pt') || voice.lang.includes('BR') || voice.lang.includes('PT')
                );
                
                if (portugueseVoices.length > 0) {
                    portugueseVoices.forEach(voice => {
                        const option = document.createElement('option');
                        option.value = voice.name;
                        option.textContent = `${voice.name} (${voice.lang})`;
                        voiceSelect.appendChild(option);
                    });
                } else {
                    // Se não houver vozes em português, usar todas as disponíveis
                    voices.forEach(voice => {
                        const option = document.createElement('option');
                        option.value = voice.name;
                        option.textContent = `${voice.name} (${voice.lang})`;
                        voiceSelect.appendChild(option);
                    });
                }
            }
            
            // Carregar vozes quando estiverem disponíveis
            if (synth.onvoiceschanged !== undefined) {
                synth.onvoiceschanged = loadVoices;
            }
            
            // Carregar vozes imediatamente se já estiverem disponíveis
            setTimeout(loadVoices, 100);
            
            // Função para limpar texto de elementos especiais
            function cleanText(text) {
                return text
                    .replace(/\s+/g, ' ')
                    .replace(/[\n\r\t]/g, ' ')
                    .replace(/[^\w\s\p{L}\p{N}.,!?;:()\-]/gu, ' ')
                    .trim();
            }
            
            // Função para ler um elemento específico
            function readElement(element) {
                if (utterance && synth.speaking) {
                    synth.cancel();
                }
                
                const rawText = element.innerText || element.textContent;
                const text = cleanText(rawText);
                
                if (!text || text.length < 3) return;
                
                utterance = new SpeechSynthesisUtterance(text);
                
                // Configurar voz selecionada
                const selectedVoice = voices.find(voice => voice.name === voiceSelect.value);
                if (selectedVoice) {
                    utterance.voice = selectedVoice;
                } else if (voices.length > 0) {
                    // Usar a primeira voz disponível se nenhuma foi selecionada
                    utterance.voice = voices[0];
                }
                
                // Configurar velocidade e tom
                utterance.rate = parseFloat(rateSelect.value);
                utterance.pitch = parseFloat(pitchSelect.value);
                utterance.volume = 1;
                
                // Destacar elemento durante a leitura
                if (currentSection) {
                    currentSection.classList.remove('highlight');
                }
                currentSection = element;
                element.classList.add('highlight');
                
                // Configurar eventos
                utterance.onend = function() {
                    element.classList.remove('highlight');
                    readNextSection();
                };
                
                utterance.onerror = function(event) {
                    console.error('Erro na síntese de voz:', event);
                    element.classList.remove('highlight');
                    readNextSection();
                };
                
                utterance.onstart = function() {
                    isReading = true;
                    updateButtons(true);
                };
                
                // Iniciar leitura
                try {
                    synth.speak(utterance);
                } catch (error) {
                    console.error('Erro ao iniciar síntese de voz:', error);
                    element.classList.remove('highlight');
                    readNextSection();
                }
            }
            
            // Função para ler a próxima seção
            function readNextSection() {
                if (currentSectionIndex < sectionQueue.length - 1) {
                    currentSectionIndex++;
                    readElement(sectionQueue[currentSectionIndex]);
                } else {
                    // Fim da leitura
                    isReading = false;
                    updateButtons(false);
                    if (currentSection) {
                        currentSection.classList.remove('highlight');
                    }
                }
            }
            
            // Função para ler todo o relatório
            function readReport() {
                const sections = document.querySelectorAll('section');
                sectionQueue = Array.from(sections);
                currentSectionIndex = 0;
                
                if (sectionQueue.length > 0) {
                    readElement(sectionQueue[currentSectionIndex]);
                } else {
                    console.error('Nenhuma seção encontrada para leitura');
                }
            }
            
            // Atualizar estado dos botões
            function updateButtons(playing) {
                playBtn.disabled = playing;
                pauseBtn.disabled = !playing || !synth.speaking;
                resumeBtn.disabled = !synth.paused;
                stopBtn.disabled = !playing;
            }
            
            // Event listeners para os botões
            playBtn.addEventListener('click', function() {
                if (voices.length === 0) {
                    alert('Aguarde o carregamento das vozes ou verifique se seu navegador suporta síntese de voz.');
                    return;
                }
                readReport();
            });
            
            pauseBtn.addEventListener('click', function() {
                if (synth.speaking && !synth.paused) {
                    synth.pause();
                    updateButtons(true);
                }
            });
            
            resumeBtn.addEventListener('click', function() {
                if (synth.paused) {
                    synth.resume();
                    updateButtons(true);
                }
            });
            
            stopBtn.addEventListener('click', function() {
                synth.cancel();
                isReading = false;
                if (currentSection) {
                    currentSection.classList.remove('highlight');
                }
                updateButtons(false);
            });
            
            // Permitir que o usuário clique em seções específicas para ouvir
            const sections = document.querySelectorAll('section');
            sections.forEach(section => {
                section.addEventListener('click', function() {
                    if (voices.length === 0) {
                        alert('Aguarde o carregamento das vozes ou verifique se seu navegador suporta síntese de voz.');
                        return;
                    }
                    sectionQueue = [this];
                    currentSectionIndex = 0;
                    readElement(this);
                });
            });
            
            // Monitorar mudanças no status da síntese de voz
            setInterval(function() {
                if (isReading && !synth.speaking && !synth.paused) {
                    // A leitura foi interrompida inesperadamente
                    isReading = false;
                    updateButtons(false);
                    if (currentSection) {
                        currentSection.classList.remove('highlight');
                    }
                }
            }, 500);
        });
    </script>
</body>
</html>